# ECO-Efficient-Convolutional-Network-for-Online-Video-Understanding

1.本文的写作背景
目前视频理解最新技术存在两个问题：（1）推理的最大问题在于它只是在视频中局部进行，因此对于几秒的动作，它丢失了动作行为之间的关系 
                               （2）虽然存在快速处理的方法，但是整个视频的处理效率不高并且妨碍了长期活动的快速视频检索或在线分类
所以，作者直接设计了一种端到端的架构来解决这些问题。作者意识到，既然单张图片已经可以对动作内容做出一定分类，那大量的邻近帧就是冗余的，所以在一个时间段内只取一帧来处理就已经够了。
此外，作者认为，与其把各个时间段的分数整合起来得到最终分数，不如整合各个时间段中的特征信息。我们可以隔一段距离取一帧，把这些图片放到3D卷积里处理，这样不仅能更好地处理时间信息，还可以处理更长时间段内的信息
2.本文提出的网络架构


网络架构如图1所示。输入的视频被分成N个子部分Si，i = 1，...，N，它们具有相同的大小，并且在每个子部分中随机采样一帧。这些帧中的每一帧都由单个2D卷积网络（权重共享）处理，其产生编码帧外观的特征表示。通过联合处理覆盖整个视频的时间段的帧确保捕获动作中最相关的部分随着时间的推移以及这些部分之间的关系。
       随机采样帧的位置优于总是使用相同的位置，因为它在训练期间导致更多的多样性并且使网络适应动作实例化的变化。同时，网络必须在运行时只处理N个帧，这使得这种方法非常快。论文也采用了更聪明的分区策略，它们将子部分的内容考虑在内。
论文中共有两个网络模型：ECO Lite和ECO Full


3.网络具体结构：
2D-Net：对于分析单帧的2D网络，使用BN-Inception架构的第一部分（直到inception-3c层）。它具有2D filters and pooling以及batch normalization。选择这种架构是因为它的效率。每个单帧的输出由96个特征图组成，大小为28×28。
3D-Net：对于3D网络（），采用了多层3D-Resnet18，这是一种用于许多视频分类工作的高效架构。的输出是不同类标签的one-hot向量。
2D-NetS：在ECO整体设计中，使用2D-Nets与3D-net并行直接提供视频的静态视觉语义。对于这个网络，文章中使用BN-Inception架构中从inception-4a层到最后一个池化层。最后一个池化层将为每个帧生成1024维特征向量。我们应用平均池来生成视频级特征，然后与从3D-net获得的特征连接。
4.训练细节：
文章中使用具有Nesterov动量的mini-batch SGD训练网络，并在每个全连接层利用dropout。将每个视频分成N个片段，并从每个片段中随机选择一个帧。这种讲降采样对变化更有鲁棒性，并使网络能够充分利用所有帧。此外，文章使用了数据增强技术：将输入帧的大小调整为240×320，并采用固定角落裁剪和水平翻转的缩放抖动（由采样提供的时间抖动）。然后运行每像素平均减法并将裁剪区域的大小调整为224×224。
5.测试时间：
大多数先进的方法对网络结果进行一些后处理。 例如，TSN和ARTNet 每个视频收集25个独立的帧，并且对于每个帧样本通过角落和中心裁剪以及它们的水平翻转得到10个区域。 通过平均所有250个样本的得分来获得最终预测。 这种在测试时的推理在计算上是昂贵的，因此不适合实时设置。相比之下，ECO网络直接为整个视频生成动作标签而无需任何额外的聚合。 从视频中采样N帧，仅应用中心裁剪，然后将它们直接馈送到网络，通过单次传递提供整个视频的预测。
6. 训练方式：

优化器： mini-Batch SGD + Nesterov momentum
Dropout
数据增强：将视频缩小到进行裁切。裁切时固定一个角，随机细微改变裁切框大小；左右翻转图像；每一个像素减去裁剪框内的像素均值；重新调整裁下区域大小到。
学习率：初始0.001，验证集错误率持续4 epoch不变时以10倍减小。
Momentum：0.9
weight decay: 0.0005
batch size: 32
权重初始条件：
2D网络：Kinetics预训练权重
3D网络：某篇参考论文[15]中的预训练权重，详情参考原论文引用列表。
针对某些特殊数据集进行了额外的微调。
